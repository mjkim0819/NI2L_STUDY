# GloVe
## 등장배경
- LSA (카운트 기반)
  - 전체적인 통계 정보(문서 전체의 각 단어의 빈도수를 담은 행렬)를 입력으로 받아 차원을 축소(Truncated SVD)하여 잠재된 의미를 끌어내는 방법론
  - 말뭉치 (corpus)의 전체적인 통계정보(단어의 빈도수)를 반영할 때 유리
- Word Embedding (예측 기반)
  - window를 사용해 문서 전체가 아니라 중심단어를 둘러싼 주변단어의 실제값과 예측값에 대한 오차를 손실 함수를 통해 줄여나가며 학습하는 방법론
  - 단어 간 유추에 뛰어난 성능 -> 말뭉치 전체가 아닌 주변 단어 몇개만 학습    
두 방식을 부분적으로 차용하여 GloVe 등장
- GloVe
  - 임베딩된 두 단어벡터의 내적이 말뭉치 전체에서의 동시 등장확률 로그값이 되도록 목적함수를 정의
  - 단어 임베딩의 선형성(내적)을 내포한 채로 문서 전체의 통계치를 반영
  
## 목적
단어 임베딩의 선형성(내적)을 내포한 채로 문서 전체의 통계치를 반영  
- 임베딩 된 "중심단어 벡터와 주변단어 벡터의 내적"이 전체 코퍼스에서의 "동시 등장 확률"이 되도록 만드는 것
  
## 윈도우 기반 동시 발생 행렬 (Window based Co-occurrence Matrix)
단어 집합의 단어로 구성된 행렬  
- i : 중심단어
- k : 주변단어
  - window size 내에서 i 주변에 나타난 k의 빈도수를 카운트
  - i행 k열에 빈도수 작성
  - 대칭행렬로 작성  
  
![image](https://github.com/mjkim0819/NI2L_STUDY/assets/108729047/d005f735-c021-4279-bb31-763b81a6ff49)  
- I like deep learning
- I like NLP
- I enjoy flying  
윈도우 크기 = 1일때 동시 발생 행렬  
  
## 동시 등장 확률 (Co-occurrence Probability)
두 단어가 등장할 조건부 확률  
- i : 중심단어
- k : 주변단어
  - 전체 단어에서 i가 등장한 횟수 카운트
  - i가 등장했을 때 k가 등장한 횟수 카운트
  - 조건부 확률 P(k∣i)

![image](https://github.com/mjkim0819/NI2L_STUDY/assets/108729047/b4bd05f1-1879-4553-8bba-218ae4c5f51e)  
  
두 단어가 비슷하게 등장하는 경우는 1과 가까이 나옴  
steam이 더 많이 등장하는 경우에는 1보다 한참 작은 값이 나옴  
ice가 더 많이 등장하는 경우에는 1보다 훨씬 큰 값이 나옴  
